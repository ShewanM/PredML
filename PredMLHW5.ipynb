{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "from mxnet import nd, autograd\n",
    "from mxnet import gluon\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "    \n",
    "\n",
    "sym, arg_params, aux_params = mx.model.load_checkpoint('pretrained/squeezenet_v1.1', 0)\n",
    "\n",
    "mod = mx.mod.Module(symbol=sym, context=mx.cpu(), label_names=None)\n",
    "mod.bind(for_training=False, data_shapes=[('data', (1,3,224,224))],label_shapes=mod._label_shapes)\n",
    "mod.set_params(arg_params, aux_params, allow_missing=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list the last 10 layers\n",
    "all_layers = sym.get_internals()\n",
    "all_layers.list_outputs()[-6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "# define a simple data batch\n",
    "from collections import namedtuple\n",
    "Batch = namedtuple('Batch', ['data'])\n",
    "\n",
    "def get_image(url, show=False):\n",
    "    if url.startswith('http'):\n",
    "        # download and show the image\n",
    "        fname = mx.test_utils.download(url)\n",
    "    else:\n",
    "        fname = url\n",
    "    img = cv2.cvtColor(cv2.imread(fname), cv2.COLOR_BGR2RGB)\n",
    "    if img is None:\n",
    "         return None\n",
    "    if show:\n",
    "         plt.imshow(img)\n",
    "         plt.axis('off')\n",
    "    # convert into format (batch, RGB, width, height)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    img = np.swapaxes(img, 0, 2)\n",
    "    img = np.swapaxes(img, 1, 2)\n",
    "    img = img[np.newaxis, :]\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_sym = all_layers['flatten0_output']\n",
    "fe_mod = mx.mod.Module(symbol=fe_sym, context=mx.cpu(), label_names=None)\n",
    "fe_mod.bind(for_training=False, data_shapes=[('data', (1,3,224,224))])\n",
    "fe_mod.set_params(arg_params, aux_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(img):\n",
    "    fe_mod.forward(Batch([mx.nd.array(img)]))\n",
    "    features = fe_mod.get_outputs()[0].asnumpy()\n",
    "    return features\n",
    "\n",
    "img = get_image('Thinking-of-getting-a-cat.png')\n",
    "features = get_features(img)\n",
    "\n",
    "#print(\"{}\\n shape: {}\".format(features,features.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/data\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "mypath = 'C:/users/Finithopian/Desktop/Chapter-5/data/train'\n",
    "cats_imgs = [join(mypath,f) for f in listdir(mypath) if f.startswith('cat')]\n",
    "dogs_imgs = [join(mypath,f) for f in listdir(mypath) if f.startswith('dog')]\n",
    "print(\"cats: {} and dogs: {}\".format(len(cats_imgs),len(dogs_imgs)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nmax = 100\n",
    "cats_features = [get_features(get_image(img)).ravel() for img in cats_imgs[:Nmax]]\n",
    "dogs_features = [get_features(get_image(img)).ravel() for img in cats_imgs[:Nmax]]\n",
    "\n",
    "Y_cats = np.array(Nmax * [1])\n",
    "Y_dogs = np.array(Nmax * [0])\n",
    "\n",
    "X_cvd = np.vstack([cats_features,dogs_features])\n",
    "Y_cvd = np.vstack([Y_cats,Y_dogs]).ravel()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_cvd, Y_cvd, random_state=42)\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Test set score: {:.2f}\".format(grid_search.score(X_test, y_test)))\n",
    "# --- OR --\n",
    "pred = grid_search.predict(X_test)\n",
    "acc_labels= accuracy_score(y_test,pred)\n",
    "print(\"accuracy\",acc_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nmax = 1000\n",
    "cats_features = [get_features(get_image(img)).ravel() for img in cats_imgs[:Nmax]]\n",
    "dogs_features = [get_features(get_image(img)).ravel() for img in cats_imgs[:Nmax]]\n",
    "\n",
    "Y_cats = np.array(Nmax * [1])\n",
    "Y_dogs = np.array(Nmax * [0])\n",
    "\n",
    "X_cvd = np.vstack([cats_features,dogs_features])\n",
    "Y_cvd = np.vstack([Y_cats,Y_dogs]).ravel()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_cvd, Y_cvd, random_state=42)\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Test set score: {:.2f}\".format(grid_search.score(X_test, y_test)))\n",
    "# --- OR --\n",
    "pred = grid_search.predict(X_test)\n",
    "acc_labels= accuracy_score(y_test,pred)\n",
    "print(\"accuracy\",acc_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nmax = 5000\n",
    "cats_features = [get_features(get_image(img)).ravel() for img in cats_imgs[:Nmax]]\n",
    "dogs_features = [get_features(get_image(img)).ravel() for img in cats_imgs[:Nmax]]\n",
    "\n",
    "Y_cats = np.array(Nmax * [1])\n",
    "Y_dogs = np.array(Nmax * [0])\n",
    "\n",
    "X_cvd = np.vstack([cats_features,dogs_features])\n",
    "Y_cvd = np.vstack([Y_cats,Y_dogs]).ravel()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_cvd, Y_cvd, random_state=42)\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Test set score: {:.2f}\".format(grid_search.score(X_test, y_test)))\n",
    "# --- OR --\n",
    "pred = grid_search.predict(X_test)\n",
    "acc_labels= accuracy_score(y_test,pred)\n",
    "print(\"accuracy\",acc_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nmax = 12500\n",
    "cats_features = [get_features(get_image(img)).ravel() for img in cats_imgs[:Nmax]]\n",
    "dogs_features = [get_features(get_image(img)).ravel() for img in cats_imgs[:Nmax]]\n",
    "\n",
    "Y_cats = np.array(Nmax * [1])\n",
    "Y_dogs = np.array(Nmax * [0])\n",
    "\n",
    "X_cvd = np.vstack([cats_features,dogs_features])\n",
    "Y_cvd = np.vstack([Y_cats,Y_dogs]).ravel()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_cvd, Y_cvd, random_state=42)\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Test set score: {:.2f}\".format(grid_search.score(X_test, y_test)))\n",
    "print(\"Test set score: {:.2f}\".format(grid_search.score(X_test, y_test)))\n",
    "# --- OR --\n",
    "pred = grid_search.predict(X_test)\n",
    "acc_labels= accuracy_score(y_test,pred)\n",
    "print(\"accuracy\",acc_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
